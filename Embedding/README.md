# Embedding

本项目主要探索基于大模型的Embedding模型。在大模型的基础上添加一层网络，构成整个embedding模型。训练时冻结大模型层，只训练添加的网络层。

## 说明

- s2s, 即 sentence to sentence ，代表了同质文本之间的嵌入能力，适用任务：文本相似度，重复问题检测，文本分类等
- s2p, 即 sentence to passage ，代表了异质文本之间的嵌入能力，适用任务：文本检索，GPT 记忆模块等
- s2c, 即 sentence to code ，代表了自然语言和程序语言之间的嵌入能力，适用任务：代码检索

## 评测 MTEB-zh

- 评测脚本和其他模型评测结果取自[uniem](https://github.com/wangyuxinwhy/uniem)项目

### 文本分类

- 数据集选择，选择开源在 HuggingFace 上的 6 种文本分类数据集，包括新闻、电商评论、股票评论、长文本等
- 评测方式，使用 MTEB 的方式进行评测，报告 Accuracy。

|                   | text2vec | m3e-small | m3e-base                      | openai                        | uer     | erlangshen                    | origin_chatglm2-6b | LLM based chatglm2-6b embedding v1 |
|-------------------|----------|-----------|-------------------------------|-------------------------------|---------|-------------------------------|--------------------|------------------------------------|
| TNews             | 0.43     | 0.4443    | 0.4827                        | 0.4594                        | 0.3539  | 0.4361                        | 0.49172            | <font color=red>0.49318</font>     |
| JDIphone          | 0.8214   | 0.8293    | <font color=red>0.8533</font> | 0.746                         | 0.8283  | 0.8356                        | 0.758349           | 0.7574                             |
| GubaEastmony      | 0.7472   | 0.712     | 0.7621                        | 0.7574                        | 0.7534  | <font color=red>0.7787</font> | 0.74035            | 0.742                              |
| TYQSentiment      | 0.6099   | 0.6596    | <font color=red>0.7188</font> | 0.68                          | 0.6662  | 0.6444                        | 0.6469             | 0.64513                            |
| StockComSentiment | 0.4307   | 0.4291    | 0.4363                        | <font color=red>0.4819</font> | 0.4555  | 0.4482                        | 0.43928            | 0.4394                             |
| IFlyTek           | 0.414    | 0.4263    | 0.4409                        | <font color=red>0.4486</font> | 0.3762  | 0.4241                        | 0.44838            | 0.45851                            |
| Average           | 0.5755   | 0.5834    | <font color=red>0.6157</font> | 0.5956                        | 0.57225 | 0.594516667                   | 0.5875             | 0.58927                            |

### 检索排序

#### T2Ranking 1W

- 数据集选择，使用 [T2Ranking](https://github.com/THUIR/T2Ranking/tree/main) 数据集，由于 T2Ranking 的数据集太大，openai
  评测起来的时间成本和 api 费用有些高，所以我们只选择了 T2Ranking 中的前 10000 篇文章
- 评测方式，使用 MTEB 的方式进行评测，报告 map@1, map@10, mrr@1, mrr@10, ndcg@1, ndcg@10
- 注意！从实验结果和训练方式来看，除了 M3E 模型和 openai 模型外，其余模型都没有做检索任务的训练，所以结果仅供参考。

|         | text2vec | openai-ada-002 | m3e-small | m3e-base   | uer     | erlangshen | origin_chatglm2-6b | LLM based chatglm2-6b embedding v1 |
|---------|----------|----------------|-----------|------------|---------|------------|--------------------|------------------------------------|
| map@1   | 0.4684   | 0.6133         | 0.5574    | **0.626**  | 0.08647 | 0.25394    | 0.00162            | 0.00162                            |
| map@10  | 0.5877   | 0.7423         | 0.6878    | **0.7656** | 0.13008 | 0.34714    | 0.00214            | 0.00263                            |
| mrr@1   | 0.5345   | 0.6931         | 0.6324    | **0.7047** | 0.10067 | 0.29447    | 0.00162            | 0.00162                            |
| mrr@10  | 0.6217   | 0.7668         | 0.712     | **0.7841** | 0.14516 | 0.3751     | 0.00218            | 0.00265                            |
| ndcg@1  | 0.5207   | 0.6764         | 0.6159    | **0.6881** | 0.09748 | 0.28578    | 0.00162            | 0.00162                            |
| ndcg@10 | 0.6346   | 0.7786         | 0.7262    | **0.8004** | 0.15783 | 0.39329    | 0.00246            | 0.00323                            |
